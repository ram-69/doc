{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6iWyZ8-fmi4",
        "outputId": "005ef3e3-f960-4d8d-ddbb-8a0965c6207b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp310-cp310-linux_x86_64.whl size=3365667 sha256=774c4a3508785e84a376c49718ba0ec92fefbf4fbd6c40d786ea2946f016930e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1b/b5/97ec4cfccdde26e0f3590ad6e09a5242d508dff09704ef86c1\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6YUeH8VdqXr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset:\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "\n",
        "#Initialize MPI\n",
        "from mpi4py import MPI\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()\n",
        "\n",
        "#Define the training function:\n",
        "def train(model, x_train, y_train, rank, size):\n",
        "  # Split the data across the nodes \n",
        "  n = len(x_train)\n",
        "  chunk_size = n // size \n",
        "  start = rank * chunk_size \n",
        "  end = (rank + 1) * chunk_size\n",
        "  if rank == size - 1:\n",
        "    end = n\n",
        "  x_train_chunk = x_train[start:end]\n",
        "  y_train_chunk = y_train[start:end]\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam',\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "  #Train the model\n",
        "  model.fit(x_train_chunk, y_train_chunk, epochs=1, batch_size=32)\n",
        "  # Compute the accuracy on the training data\n",
        "  train_loss, train_acc = model.evaluate(x_train_chunk, y_train_chunk, verbose=2)\n",
        "  # Reduce the accuracy across all nodes\n",
        "  train_acc = comm.allreduce(train_acc, op=MPI.SUM)\n",
        "  return train_acc / size\n"
      ],
      "metadata": {
        "id": "Ybfi9eWOdzo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Run the training loop:\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  # Train the model\n",
        "  train_acc = train(model, x_train, y_train, rank, size)\n",
        "  # Compute the accuracy on the test data\n",
        "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "  # Reduce the accuracy across all nodes\n",
        "  test_acc = comm.allreduce(test_acc, op=MPI.SUM)\n",
        "  # Print the results if rank == 0:\n",
        "  #print(f\"Epoch {epoch + 1}: Train accuracy = {train_acc:.4f}, Test accuracy = {test_acc:.4f}\")\n",
        "  print(f\"Epoch {epoch + 1}: Train accuracy = {train_acc:.4f}, Test accuracy = {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-jLNtwcemG-",
        "outputId": "bb489943-b517-4cf7-c374-3981cf9f42f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0352 - accuracy: 0.9895\n",
            "1875/1875 - 12s - loss: 0.0267 - accuracy: 0.9925 - 12s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0544 - accuracy: 0.9826 - 2s/epoch - 6ms/step\n",
            "Epoch 1: Train accuracy = 0.9925, Test accuracy = 0.9826\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0300 - accuracy: 0.9911\n",
            "1875/1875 - 11s - loss: 0.0218 - accuracy: 0.9936 - 11s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0552 - accuracy: 0.9834 - 2s/epoch - 6ms/step\n",
            "Epoch 2: Train accuracy = 0.9936, Test accuracy = 0.9834\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0257 - accuracy: 0.9925\n",
            "1875/1875 - 12s - loss: 0.0195 - accuracy: 0.9941 - 12s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0597 - accuracy: 0.9822 - 2s/epoch - 6ms/step\n",
            "Epoch 3: Train accuracy = 0.9941, Test accuracy = 0.9822\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0222 - accuracy: 0.9936\n",
            "1875/1875 - 12s - loss: 0.0159 - accuracy: 0.9954 - 12s/epoch - 7ms/step\n",
            "313/313 - 2s - loss: 0.0556 - accuracy: 0.9837 - 2s/epoch - 7ms/step\n",
            "Epoch 4: Train accuracy = 0.9954, Test accuracy = 0.9837\n",
            "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0189 - accuracy: 0.9944\n",
            "1875/1875 - 12s - loss: 0.0140 - accuracy: 0.9963 - 12s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0587 - accuracy: 0.9834 - 2s/epoch - 6ms/step\n",
            "Epoch 5: Train accuracy = 0.9963, Test accuracy = 0.9834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rCWJ4fsugBcG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}